{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d858b4",
   "metadata": {},
   "source": [
    "# Appendix A.2: Computational Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83589cf3",
   "metadata": {},
   "source": [
    "This notebook reproduces the analyses in the Appendix, Section A.2 of the manuscript, including Tables 1-3.\n",
    "\n",
    "> **Note:** By default, the computational cost experiments are run in parallel on 6 cores. If you have less cores available on your system, you should change that number according to your resources: `addprocs(5)` means that 5 processes on separates cores are added to the one being used already, so if you want to use, e.g., 4 cores, change that to `addprocs(3)`. If you do not want to run the code in parallel or have no sufficient resources to do to, you can comment out the line altogether and the code will run without further changes on a single core. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096dbe5",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef471b80",
   "metadata": {},
   "source": [
    "First, we set up the parallel computing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fd550e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Int64}:\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea367f4f",
   "metadata": {},
   "source": [
    "Next, we load the Julia environment specified in the `Project.toml` and `Manifest.toml` files: First, we activate this environment, then install all dependencies (if some packages are not yet installed), and print out which packages and versions are currently in our environment. To make it available on all used processes, we use the `@everywhere` macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb69eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 10:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 8:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 11:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 9:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 7:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 5:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 2:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 6:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 3:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n",
      "      From worker 4:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Desktop/DeepDynamicModelingWithJust2TimePoints/Project.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mBenchmarkTools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m  ✓ \u001b[39mPlots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2 dependencies successfully precompiled in 33 seconds (278 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "@everywhere using Pkg; \n",
    "\n",
    "# all paths are relative to the `notebook` subfolder main folder, i.e., assuming `pwd()` outputs\n",
    "# \".../DeepDynamicodelingWithJust2TimePoints/notebooks\"\n",
    "\n",
    "@everywhere Pkg.activate(\"../.\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6b3ca",
   "metadata": {},
   "source": [
    "Next, we load and precompile the necessary packages (in the versions specified by the `*.toml` files). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f4c3d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using BenchmarkTools\n",
    "@everywhere using DataFrames\n",
    "@everywhere using Distributed\n",
    "@everywhere using Distributions\n",
    "@everywhere using Random\n",
    "@everywhere using Flux\n",
    "@everywhere using DiffEqFlux\n",
    "@everywhere using OrdinaryDiffEq\n",
    "@everywhere using SharedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e43804",
   "metadata": {},
   "source": [
    "Additionally, we import some user-defined functions, with different files for separate functionality, also using `@everywhere` to define them on all procs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc0ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere include(\"../src/simulation.jl\") # for simulating data\n",
    "@everywhere include(\"../src/model.jl\") # for initializing and training the model\n",
    "@everywhere include(\"../src/benchmarking.jl\") # for plotting data and learned trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff4b24e",
   "metadata": {},
   "source": [
    "## Define ground truth developments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0008a8e",
   "metadata": {},
   "source": [
    "First, we define the ground-truth developments as solutions of the underlying two-dimensional linear ODE system with two distinct sets of parameters, corresponding to two groups of individuals with two distinct underlying development patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0048263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial condition\n",
    "@everywhere true_u0 = Float32[2, 1]\n",
    "# define time span on which to solve the ODE\n",
    "@everywhere tspan = (0.0f0, 10.0f0)\n",
    "# define parameters for the two distinct groups\n",
    "@everywhere true_odeparams_group1 = Float32[-0.2, 0.00, 0.00, -0.2]\n",
    "@everywhere true_odeparams_group2 = Float32[-0.2, 0.00, 0.00, 0.2]\n",
    "  \n",
    "# define corresponding ODE problems for the two groups\n",
    "@everywhere prob1 = ODEProblem(linear_2d_system,true_u0,tspan,true_odeparams_group1)\n",
    "@everywhere prob2 = ODEProblem(linear_2d_system,true_u0,tspan,true_odeparams_group2)\n",
    "  \n",
    "# solve ODE systems to obtain \"true\" underlying trajectory in each group\n",
    "@everywhere dt=0.1\n",
    "@everywhere sol_group1 = solve(prob1, Tsit5(), saveat = dt);\n",
    "@everywhere sol_group2 = solve(prob2, Tsit5(), saveat = dt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb8178",
   "metadata": {},
   "source": [
    "## Train model using benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb01eb5",
   "metadata": {},
   "source": [
    "Now, we train the model on varying numbers of individuals, time-dependent variables and baseline variables. We save all benchmark results, i.e., runtime, memory, and allocations, in a specific `SharedArray`, an array that allows for being used simultaneous by different processes while preventing them from getting in the way of each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29518a41",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b899fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of observations, variables and baseline variables to try \n",
    "@everywhere n_obs = [50, 100, 250, 500, 1000, 2000, 5000]\n",
    "@everywhere n_vars = [10, 20, 50, 100, 200]\n",
    "@everywhere n_baselinevars = [10, 20, 50, 100, 200]\n",
    "@everywhere lenobs, lenvars, lenbvars = length(n_obs), length(n_vars), length(n_baselinevars)\n",
    "\n",
    "# construct dataframe: n, p, q, time, memory, allocations\n",
    "benchmarkdf = DataFrame(n_obs = cat(n_obs, fill(100, lenvars + lenbvars), dims=1),\n",
    "        n_vars = cat(fill(10, lenobs), n_vars, fill(10, lenbvars), dims=1),\n",
    "        n_baselinevars = cat(fill(50, lenobs + lenvars), n_baselinevars, dims=1),\n",
    "        time = fill(0.0, lenobs+lenvars+lenbvars),\n",
    "        gctime = fill(0.0, lenobs+lenvars+lenbvars),\n",
    "        memory = fill(0, lenobs+lenvars+lenbvars),\n",
    "        allocs = fill(0, lenobs+lenvars+lenbvars)\n",
    ")\n",
    "\n",
    "# get it to a shared array for distributed computing\n",
    "benchmarkarray = SharedArrays.SharedMatrix{Float64}(size(Matrix(benchmarkdf)));\n",
    "benchmarkarray[:,1:3] = Matrix(benchmarkdf)[:,1:3];\n",
    "\n",
    "@everywhere eval($benchmarkarray);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6fb13",
   "metadata": {},
   "source": [
    "### Scenario 1: Fixed number of time-dep and baseline variables, varying number of observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8032912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\twarmup done\n",
      "      From worker 8:\tn=5000, p=10, q=50\n",
      "      From worker 7:\twarmup done\n",
      "      From worker 7:\tn=2000, p=10, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 6:\twarmup done\n",
      "      From worker 6:\tn=1000, p=10, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\twarmup done\n",
      "      From worker 4:\tn=250, p=10, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 2:\twarmup done\n",
      "      From worker 2:\tn=50, p=10, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 5:\twarmup done\n",
      "      From worker 5:\tn=500, p=10, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\twarmup done\n",
      "      From worker 3:\tn=100, p=10, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 2:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 5:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 6:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\ttraining done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x0000000160b7c010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@sync @distributed for n_ind in 1:lenobs\n",
    "    # warmup (first run takes longer because of precompilation times and shouldnt be included)\n",
    "    n_warmup, p_warmup, q_warmup, q_info_warmup = 100, 10, 10, 10\n",
    "    xs, x_baseline, tvals, group1, group2 = generate_all(n_warmup, p_warmup, q_warmup, q_info_warmup);\n",
    "    trainingdata = zip(xs, x_baseline, tvals);\n",
    "    zdim = nODEparams = 2\n",
    "    m = init_vae(p_warmup, q_warmup, zdim, nODEparams, prob1)\n",
    "    L = loss_wrapper(m)\n",
    "    ps = getparams(m)\n",
    "    opt = ADAM(0.0005)\n",
    "    for epoch in 1:35\n",
    "        Flux.train!(L, ps, trainingdata, opt)\n",
    "    end\n",
    "    println(\"warmup done\")\n",
    "    # now start for real\n",
    "    n, p, q = n_obs[n_ind], 10, 50 \n",
    "    println(\"n=$n, p=$p, q=$q\")\n",
    "    q_info = Int(q/5)\n",
    "    xs, x_baseline, tvals, group1, group2 = generate_all(n, p, q, q_info);\n",
    "    trainingdata = zip(xs, x_baseline, tvals);\n",
    "    zdim = nODEparams = 2\n",
    "    m = init_vae(p, q, zdim, nODEparams, prob1)\n",
    "    b = @benchmark run_benchmark($trainingdata, $m) samples=1 evals=1\n",
    "    println(\"training done\")\n",
    "    row = n_ind\n",
    "    benchmarkarray[row,4] = b.times[1] # times\n",
    "    benchmarkarray[row,5] = b.gctimes[1] # gctimes \n",
    "    benchmarkarray[row,6] = b.memory # memory \n",
    "    benchmarkarray[row,7] = b.allocs # allocations\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751fcf3",
   "metadata": {},
   "source": [
    "### Scenario 2: Fixed number of observations and baseline variables, varying number of time-dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7680a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\tn=100, p=200, q=50\n",
      "      From worker 2:\tn=100, p=100, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 10:\tn=100, p=20, q=50\n",
      "      From worker 11:\tn=100, p=50, q=50\n",
      "      From worker 9:\tn=100, p=10, q=50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 2:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 9:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 10:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 11:\ttraining done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000015c8a8cd0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@sync @distributed for p_ind in 1:lenvars\n",
    "    n, p, q = 100, n_vars[p_ind], 50 \n",
    "    println(\"n=$n, p=$p, q=$q\")\n",
    "    q_info = Int(q/5)\n",
    "    xs, x_baseline, tvals, group1, group2 = generate_all(n, p, q, q_info);\n",
    "    trainingdata = zip(xs, x_baseline, tvals);\n",
    "    zdim = nODEparams = 2\n",
    "    m = init_vae(p, q, zdim, nODEparams, prob1)\n",
    "    b = @benchmark run_benchmark($trainingdata, $m) samples=1 evals=1\n",
    "    println(\"training done\")\n",
    "    row = lenobs + p_ind\n",
    "    benchmarkarray[row,4] = b.times[1] # times\n",
    "    benchmarkarray[row,5] = b.gctimes[1] # gctimes \n",
    "    benchmarkarray[row,6] = b.memory # memory \n",
    "    benchmarkarray[row,7] = b.allocs # allocations\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fe0f0",
   "metadata": {},
   "source": [
    "### Scenario 3: Fixed number of observations and time-dependent variables, varying number of baseline variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808b0839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\tn=100, p=10, q=200\n",
      "      From worker 7:\tn=100, p=10, q=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 5:\tn=100, p=10, q=20\n",
      "      From worker 6:\tn=100, p=10, q=50\n",
      "      From worker 4:\tn=100, p=10, q=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 5:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 6:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\ttraining done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\ttraining done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000015d685000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@sync @distributed for q_ind in 1:lenbvars\n",
    "    n, p, q = 100, 10, n_baselinevars[q_ind]\n",
    "    println(\"n=$n, p=$p, q=$q\")\n",
    "    q_info = Int(q/5)\n",
    "    xs, x_baseline, tvals, group1, group2 = generate_all(n, p, q, q_info);\n",
    "    trainingdata = zip(xs, x_baseline, tvals);\n",
    "    zdim = nODEparams = 2\n",
    "    m = init_vae(p, q, zdim, nODEparams, prob1)\n",
    "    b = @benchmark run_benchmark($trainingdata, $m) samples=1 evals=1\n",
    "    println(\"training done\")\n",
    "    row = lenobs + lenvars + q_ind\n",
    "    benchmarkarray[row,4] = b.times[1] # times\n",
    "    benchmarkarray[row,5] = b.gctimes[1] # gctimes \n",
    "    benchmarkarray[row,6] = b.memory # memory \n",
    "    benchmarkarray[row,7] = b.allocs # allocations\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53220a",
   "metadata": {},
   "source": [
    "## Save results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e175a03",
   "metadata": {},
   "source": [
    "First, we can optionally save the Julia object as `JLD2` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0316f219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17×7 SharedMatrix{Float64}:\n",
       "   50.0   10.0   50.0  1.01433e10  2.93438e8   1.69195e9   1.74255e7\n",
       "  100.0   10.0   50.0  1.73471e10  5.37488e8   3.38413e9   3.48681e7\n",
       "  250.0   10.0   50.0  3.82571e10  1.27961e9   8.46083e9   8.72037e7\n",
       "  500.0   10.0   50.0  6.55462e10  2.26986e9   1.69226e10  1.74469e8\n",
       " 1000.0   10.0   50.0  1.2202e11   4.36639e9   3.38457e10  3.48972e8\n",
       " 2000.0   10.0   50.0  1.92253e11  8.15655e9   6.76973e10  6.97948e8\n",
       " 5000.0   10.0   50.0  4.29818e11  2.05297e10  1.6924e11   1.74553e9\n",
       "  100.0   10.0   50.0  1.03624e10  4.07309e8   3.38414e9   3.48682e7\n",
       "  100.0   20.0   50.0  1.14628e10  4.50933e8   3.92182e9   4.46941e7\n",
       "  100.0   50.0   50.0  1.4565e10   7.2731e8    5.93587e9   7.40914e7\n",
       "  100.0  100.0   50.0  4.22082e10  3.40051e9   1.06393e10  1.23093e8\n",
       "  100.0  200.0   50.0  6.55702e10  1.04543e10  2.505e10    2.21107e8\n",
       "  100.0   10.0   10.0  1.39213e10  4.64147e8   3.30699e9   3.4867e7\n",
       "  100.0   10.0   20.0  1.42164e10  4.57695e8   3.31784e9   3.48601e7\n",
       "  100.0   10.0   50.0  1.4241e10   4.74915e8   3.38413e9   3.48681e7\n",
       "  100.0   10.0  100.0  1.42828e10  4.65251e8   3.60633e9   3.48633e7\n",
       "  100.0   10.0  200.0  1.44363e10  6.68188e8   4.47325e9   3.4914e7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if desired: save as JLD2 file \n",
    "using JLD2 \n",
    "JLD2.@save \"benchmarkresults.jld2\" benchmarkarray\n",
    "# and re-load from saved\n",
    "JLD2.@load \"benchmarkresults.jld2\" \n",
    "benchmarkarray = eval(:benchmarkarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bedcb",
   "metadata": {},
   "source": [
    "Now, we copy back the information from the `SharedArray` object to the benchmark dataframe, to export that to CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75bd42c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17-element Vector{Float64}:\n",
       " 1.7425528e7\n",
       " 3.4868112e7\n",
       " 8.7203655e7\n",
       " 1.74469471e8\n",
       " 3.48971551e8\n",
       " 6.97947943e8\n",
       " 1.745529024e9\n",
       " 3.4868182e7\n",
       " 4.4694106e7\n",
       " 7.4091394e7\n",
       " 1.23092985e8\n",
       " 2.21107247e8\n",
       " 3.4867032e7\n",
       " 3.4860097e7\n",
       " 3.4868112e7\n",
       " 3.4863294e7\n",
       " 3.4914004e7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copy back to dataframe, to be saved later as CSV\n",
    "benchmarkdf[:,:time] = benchmarkarray[:,4]\n",
    "benchmarkdf[:,:gctime] = benchmarkarray[:,5]\n",
    "benchmarkdf[:,:memory] = benchmarkarray[:,6]\n",
    "benchmarkdf[:,:allocs] = benchmarkarray[:,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44736c24",
   "metadata": {},
   "source": [
    "Additionally, we turn the time and memory information into human-readable format and units: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3df5c3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17-element Vector{String}:\n",
       " \"1.58 GiB\"\n",
       " \"3.15 GiB\"\n",
       " \"7.88 GiB\"\n",
       " \"15.76 GiB\"\n",
       " \"31.52 GiB\"\n",
       " \"63.05 GiB\"\n",
       " \"157.62 GiB\"\n",
       " \"3.15 GiB\"\n",
       " \"3.65 GiB\"\n",
       " \"5.53 GiB\"\n",
       " \"9.91 GiB\"\n",
       " \"23.33 GiB\"\n",
       " \"3.08 GiB\"\n",
       " \"3.09 GiB\"\n",
       " \"3.15 GiB\"\n",
       " \"3.36 GiB\"\n",
       " \"4.17 GiB\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmarkdf[:,:time_in_seconds] = round.(benchmarkarray[:,4] .* 1e-9, digits=3)\n",
    "\n",
    "# turn memory into human-readable format (taken from BenchmarkTools.jl source code)\n",
    "benchmarkdf[:,:prettymemory] = prettymemory.(benchmarkarray[:,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2fa5a4",
   "metadata": {},
   "source": [
    "Finally, we can export to CSV; re-creating Tables 1-3 from the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa7e761a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"benchmarkresults_baselinevars.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save entire dataframe as CSV\n",
    "using CSV \n",
    "CSV.write(\"benchmarkresults.csv\", benchmarkdf)\n",
    "\n",
    "# extract tables as in manuscript appendix and save as CSV files\n",
    "\n",
    "# different number of observations for fixed p (10) and q (50)\n",
    "rows_obs = findall(x -> x.n_vars == 10 && x.n_baselinevars == 50, eachrow(benchmarkdf))\n",
    "times_obs = benchmarkdf[rows_obs, [:n_obs, :time_in_seconds, :prettymemory]]\n",
    "CSV.write(\"benchmarkresults_obs.csv\", times_obs)\n",
    "\n",
    "rows_vars = findall(x -> x.n_obs == 100 && x.n_baselinevars == 50, eachrow(benchmarkdf))\n",
    "times_vars = benchmarkdf[rows_vars, [:n_vars, :time_in_seconds, :prettymemory]]\n",
    "CSV.write(\"benchmarkresults_vars.csv\", times_vars)\n",
    "\n",
    "rows_bvars = findall(x -> x.n_obs == 100 && x.n_vars == 10, eachrow(benchmarkdf))\n",
    "times_bvars = benchmarkdf[rows_bvars, [:n_baselinevars, :time_in_seconds, :prettymemory]]\n",
    "CSV.write(\"benchmarkresults_baselinevars.csv\", times_bvars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
